{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW3: Decision Tree, AdaBoost and Random Forest\n",
    "In hw3, you need to implement decision tree, adaboost and random forest by using only numpy, then train your implemented model by the provided dataset. TA will use the on-hold test label to evaluate your model performance.\n",
    "\n",
    "Please note that only **NUMPY** can be used to implement your model, you will get no points by simply calling `sklearn.tree.DecisionTreeClassifier`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "Gini Index or Entropy is often used for measuring the “best” splitting of the data. Please compute the Entropy and Gini Index of provided data. Please use the formula from [page 5 of hw3 slides](https://docs.google.com/presentation/d/1kIe_-YZdemRMmr_3xDy-l0OS2EcLgDH7Uan14tlU5KE/edit#slide=id.gd542a5ff75_0_15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy and paste your implementations right here to check your result\n",
    "# (Of course you can add your classes not written here)\n",
    "from math import log2\n",
    "import numpy as np\n",
    "\n",
    "def gini(sequence):\n",
    "\n",
    "    _, count = np.unique(sequence, return_counts=True)\n",
    "    p = count / len(sequence)\n",
    "    sumPj = np.sum(p ** 2)\n",
    "    return 1 - sumPj\n",
    "\n",
    "def entropy(sequence):\n",
    "\n",
    "    _, count = np.unique(sequence, return_counts=True)\n",
    "    p = count / len(sequence)\n",
    "    sumPlogP = np.sum(p * np.log2(p))\n",
    "    return -sumPlogP\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 = class 1,\n",
    "# 2 = class 2\n",
    "data = np.array([1,2,1,1,1,1,2,2,1,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini of data is  0.4628099173553719\n"
     ]
    }
   ],
   "source": [
    "print(\"Gini of data is \", gini(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy of data is  0.9456603046006401\n"
     ]
    }
   ],
   "source": [
    "print(\"Entropy of data is \", entropy(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "It is a binary classifiation dataset that classify if price is high or not for a cell phone, the label is stored in `price_range` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1200, 21)\n",
      "(300, 21)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>battery_power</th>\n",
       "      <th>blue</th>\n",
       "      <th>clock_speed</th>\n",
       "      <th>dual_sim</th>\n",
       "      <th>fc</th>\n",
       "      <th>four_g</th>\n",
       "      <th>int_memory</th>\n",
       "      <th>m_dep</th>\n",
       "      <th>mobile_wt</th>\n",
       "      <th>n_cores</th>\n",
       "      <th>...</th>\n",
       "      <th>px_height</th>\n",
       "      <th>px_width</th>\n",
       "      <th>ram</th>\n",
       "      <th>sc_h</th>\n",
       "      <th>sc_w</th>\n",
       "      <th>talk_time</th>\n",
       "      <th>three_g</th>\n",
       "      <th>touch_screen</th>\n",
       "      <th>wifi</th>\n",
       "      <th>price_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1583</td>\n",
       "      <td>1</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0.7</td>\n",
       "      <td>148</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>942</td>\n",
       "      <td>1651</td>\n",
       "      <td>1704</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>745</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0.8</td>\n",
       "      <td>102</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>89</td>\n",
       "      <td>1538</td>\n",
       "      <td>2459</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>832</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>0.7</td>\n",
       "      <td>103</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>125</td>\n",
       "      <td>1504</td>\n",
       "      <td>1799</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1175</td>\n",
       "      <td>1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0.3</td>\n",
       "      <td>164</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>873</td>\n",
       "      <td>1394</td>\n",
       "      <td>1944</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>695</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0.6</td>\n",
       "      <td>196</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1649</td>\n",
       "      <td>1829</td>\n",
       "      <td>2855</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   battery_power  blue  clock_speed  dual_sim  fc  four_g  int_memory  m_dep  \\\n",
       "0           1583     1          2.1         1  11       0          14    0.7   \n",
       "1            745     1          0.6         1   5       0          35    0.8   \n",
       "2            832     0          0.7         1   2       1          39    0.7   \n",
       "3           1175     1          1.3         0   2       0          19    0.3   \n",
       "4            695     0          0.5         0  18       1          12    0.6   \n",
       "\n",
       "   mobile_wt  n_cores  ...  px_height  px_width   ram  sc_h  sc_w  talk_time  \\\n",
       "0        148        7  ...        942      1651  1704    17    13          2   \n",
       "1        102        8  ...         89      1538  2459    14     1         16   \n",
       "2        103        4  ...        125      1504  1799     5     2         11   \n",
       "3        164        7  ...        873      1394  1944     9     4          9   \n",
       "4        196        2  ...       1649      1829  2855    16    13          7   \n",
       "\n",
       "   three_g  touch_screen  wifi  price_range  \n",
       "0        1             0     1            1  \n",
       "1        1             1     0            0  \n",
       "2        1             0     1            0  \n",
       "3        1             1     0            0  \n",
       "4        1             1     1            1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv('train.csv')\n",
    "val_df = pd.read_csv('val.csv')\n",
    "print(train_df.shape)\n",
    "print(val_df.shape)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "Implement the Decision Tree algorithm (CART, Classification and Regression Trees) and trained the model by the given arguments, and print the accuracy score on the validation data. You should implement two arguments for the Decision Tree algorithm\n",
    "1. **criterion**: The function to measure the criterionValue of a split. Your model should support `gini` for the Gini impurity and `entropy` for the information gain. \n",
    "2. **max_depth**: The maximum depth of the tree. If `max_depth=None`, then nodes are expanded until all leaves are pure. `max_depth=1` equals to split data once\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_df.drop(['price_range'], axis=\"columns\").values\n",
    "y_train = train_df['price_range'].values\n",
    "\n",
    "x_val = val_df.drop(['price_range'], axis=\"columns\").values\n",
    "y_val = val_df['price_range'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class Node():\n",
    "    def __init__(self, index=None, threshold=None, left=None, right=None, criterionValue=None, leafValue=None):\n",
    "        self.index = index # decision node\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.criterionValue = criterionValue\n",
    "        self.leafValue = leafValue # leaf node\n",
    "\n",
    "\n",
    "class DecisionTree():\n",
    "    def __init__(self, criterion='gini', max_depth=None, max_features=None):\n",
    "        self.criterion = criterion\n",
    "        self.max_depth = max_depth # stopping conditions\n",
    "        self.max_features = max_features # * for random forest *\n",
    "        self.root = None\n",
    "        self.depth = 0\n",
    "        self.featureCount = 0 # how many features\n",
    "        self.used = None # the features used\n",
    "\n",
    "    def fit(self, x_data, y_data):\n",
    "\n",
    "        self.featureCount = x_data.shape[1]\n",
    "        # combine the data\n",
    "        y_data = y_data.reshape(-1, 1)\n",
    "        data = np.concatenate((x_data, y_data), axis=1)\n",
    "        self.root = self.build(data)\n",
    "\n",
    "    def build(self, data, depth=1):\n",
    "\n",
    "        x_data, y_data = data[:, :-1], data[:, -1]\n",
    "        sample, feature = np.shape(x_data)\n",
    "\n",
    "        # * for random forest, set the feature number to maximum features *\n",
    "        if self.max_features is not None:\n",
    "            feature = self.max_features\n",
    "\n",
    "        if self.max_depth is None:\n",
    "            self.max_depth = sample\n",
    "\n",
    "        # split until stopping condition\n",
    "        if depth <= self.max_depth:\n",
    "            # find the best split\n",
    "            bestSplits = self.bestSplit(data, feature)\n",
    "            \n",
    "            # can further split\n",
    "            if len(bestSplits) != 0:\n",
    "                if bestSplits[\"criterionValue\"] > 0:\n",
    "                    l = self.build(bestSplits[\"left\"], depth+1)\n",
    "                    r = self.build(bestSplits[\"right\"], depth+1)\n",
    "                    # return decision node\n",
    "                    return Node(bestSplits[\"index\"], bestSplits[\"threshold\"], l, r, bestSplits[\"criterionValue\"])\n",
    "\n",
    "        # return leaf node\n",
    "        return Node(leafValue=max(list(y_data), key=list(y_data).count))\n",
    "\n",
    "    def bestSplit(self, data, feature):\n",
    "        \n",
    "        bestSplits = {} # store the stuff for the best split\n",
    "        bestCriterionValue = -float(\"inf\")\n",
    "\n",
    "        if feature == self.featureCount:\n",
    "            featureIndex = [i for i in range(self.featureCount)]\n",
    "        else:\n",
    "            # * for random forest *\n",
    "            featureIndex = random.sample(range(self.featureCount), feature)\n",
    "\n",
    "        # loop over all the features\n",
    "        for index in featureIndex:\n",
    "            featureValue = data[:, index]\n",
    "            candidate = np.unique(featureValue)\n",
    "            bestCriterionAttribute = []\n",
    "            for i in range(len(candidate)-1):\n",
    "                chosen = (candidate[i] + candidate[i+1]) / 2\n",
    "                bestCriterionAttribute.append(chosen) # take the median\n",
    "\n",
    "            # for all features\n",
    "            for attr in bestCriterionAttribute:\n",
    "                # get current split\n",
    "                left = np.array([row for row in data if row[index] <= attr])\n",
    "                right = np.array([row for row in data if row[index] > attr])\n",
    "\n",
    "                # if both have child\n",
    "                if len(left) > 0 and len(right) > 0:\n",
    "                    node = data[:, -1]\n",
    "                    l, r = left[:, -1], right[:, -1]\n",
    "\n",
    "                    # calculate the weighted information gain\n",
    "                    weight_l = len(l) / len(node)\n",
    "                    weight_r = len(r) / len(node)\n",
    "                    if self.criterion == \"gini\":\n",
    "                        value = gini(node) - (weight_l * gini(l) + weight_r * gini(r))\n",
    "                    else:\n",
    "                        value = entropy(node) - (weight_l * entropy(l) + weight_r * entropy(r))\n",
    "                        \n",
    "                    # update the best criterion value    \n",
    "                    if value > bestCriterionValue:\n",
    "                        bestSplits[\"index\"] = index\n",
    "                        bestSplits[\"threshold\"] = attr\n",
    "                        bestSplits[\"left\"] = left\n",
    "                        bestSplits[\"right\"] = right\n",
    "                        bestSplits[\"criterionValue\"] = value\n",
    "                        bestCriterionValue = value\n",
    "\n",
    "        # return best split\n",
    "        return bestSplits\n",
    "\n",
    "    def predict(self, x_data):\n",
    "\n",
    "        # predict for each data\n",
    "        preditions = [self.prediction(x, self.root) for x in x_data]\n",
    "        return preditions\n",
    "\n",
    "    def prediction(self, x_data, tree):\n",
    "\n",
    "        # it's a leaf\n",
    "        if tree.leafValue is not None: \n",
    "            return tree.leafValue\n",
    "\n",
    "        # if not, go deeper\n",
    "        if x_data[tree.index] <= tree.threshold: \n",
    "            return self.prediction(x_data, tree.left)\n",
    "        else:\n",
    "            return self.prediction(x_data, tree.right)\n",
    "\n",
    "    def Importance(self): # * for plotting *\n",
    "\n",
    "        self.used = np.zeros(self.featureCount)\n",
    "        self.traverse(self.root)\n",
    "\n",
    "        return self.used\n",
    "\n",
    "    def traverse(self, node): # * for plotting *\n",
    "\n",
    "        if node.left and node.left.criterionValue is not None:\n",
    "            self.traverse(node.left)\n",
    "        if node.right and node.right.criterionValue is not None:\n",
    "            self.traverse(node.right)\n",
    "            \n",
    "        self.used[node.index] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2.1\n",
    "Using `criterion=gini`, showing the accuracy score of validation data by `max_depth=3` and `max_depth=10`, respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree (criterion=gini, max_depth=3) accuracy: 0.92\n",
      "Decision Tree (criterion=gini, max_depth=10) accuracy: 0.94\n"
     ]
    }
   ],
   "source": [
    "def accuracy(pred, val):\n",
    "    pred = np.array(pred)\n",
    "    val = np.array(val)\n",
    "    return np.sum(pred == val)/len(val)\n",
    "\n",
    "clf_depth3 = DecisionTree(criterion='gini', max_depth=3)\n",
    "clf_depth3.fit(x_train, y_train)\n",
    "y_pred = clf_depth3.predict(x_val)\n",
    "print(\"Decision Tree (criterion=gini, max_depth=3) accuracy:\", accuracy(y_pred, y_val))\n",
    "\n",
    "clf_depth10 = DecisionTree(criterion='gini', max_depth=10)\n",
    "clf_depth10.fit(x_train, y_train)\n",
    "y_pred = clf_depth10.predict(x_val)\n",
    "print(\"Decision Tree (criterion=gini, max_depth=10) accuracy:\", accuracy(y_pred, y_val))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2.2\n",
    "Using `max_depth=3`, showing the accuracy score of validation data by `criterion=gini` and `criterion=entropy`, respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree (criterion=gini, max_depth=3) accuracy: 0.92\n",
      "Decision Tree (criterion=gini, max_depth=10) accuracy: 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "clf_gini = DecisionTree(criterion='gini', max_depth=3)\n",
    "clf_gini.fit(x_train, y_train)\n",
    "y_pred = clf_gini.predict(x_val)\n",
    "print(\"Decision Tree (criterion=gini, max_depth=3) accuracy:\", accuracy(y_pred, y_val))\n",
    "\n",
    "clf_entropy = DecisionTree(criterion='entropy', max_depth=3)\n",
    "clf_entropy.fit(x_train, y_train)\n",
    "y_pred = clf_entropy.predict(x_val)\n",
    "print(\"Decision Tree (criterion=gini, max_depth=10) accuracy:\", accuracy(y_pred, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Note: Your decisition tree scores should over **0.9**. It may suffer from overfitting, if so, you can tune the hyperparameter such as `max_depth`\n",
    "- Note: You should get the same results when re-building the model with the same arguments,  no need to prune the trees\n",
    "- Hint: You can use the recursive method to build the nodes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "Plot the [feature importance](https://sefiks.com/2020/04/06/feature-importance-in-decision-trees/) of your Decision Tree model. You can get the feature importance by counting the feature used for splitting data.\n",
    "\n",
    "- You can simply plot the **counts of feature used** for building tree without normalize the importance. Take the figure below as example, outlook feature has been used for splitting for almost 50 times. Therefore, it has the largest importance\n",
    "\n",
    "![image](https://i2.wp.com/sefiks.com/wp-content/uploads/2020/04/c45-fi-results.jpg?w=481&ssl=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Feature Importance')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "f = clf_depth10.Importance()\n",
    "feature_names = list(train_df.columns)\n",
    "feature_names.pop()  # Pop the \"target column\"\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.barh(feature_names, f)\n",
    "plt.title(\"Feature Importance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "implement the AdaBooest algorithm by using the CART you just implemented from question 2 as base learner. You should implement one arguments for the AdaBooest.\n",
    "1. **n_estimators**: The maximum number of estimators at which boosting is terminated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class AdaBoost():\n",
    "    def __init__(self, n_estimators=10):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.predicts = [] # for predictors weights\n",
    "\n",
    "    def fit(self, x_data, y_data):\n",
    "        \n",
    "        sample, feature = x_data.shape\n",
    "        self.x_data = x_data\n",
    "        self.y_data = y_data\n",
    "\n",
    "        x = self.x_data # for fitting\n",
    "        y = self.y_data\n",
    "\n",
    "        signedY = y_data.copy()\n",
    "        signedY[y_data == 0] = -1\n",
    "\n",
    "        # uniform weight distribution\n",
    "        sampleWeight = np.full(sample, 1/sample)\n",
    "\n",
    "        for epoch in range(self.n_estimators):\n",
    "\n",
    "            # train the weak classifiers\n",
    "            weak_clf = DecisionTree(criterion='gini', max_depth=1)\n",
    "            weak_clf.fit(x, y)\n",
    "            y_pred = weak_clf.predict(self.x_data)\n",
    "            for i in range(len(y_pred)): # change the range from 0 and 1 to -1 and 1\n",
    "                if y_pred[i] == 0:\n",
    "                    y_pred[i] = -1\n",
    "\n",
    "            # minimize the weighted error\n",
    "            error = np.sum(sampleWeight[y_pred != signedY])\n",
    "\n",
    "            # calculate the weight classifier alpha\n",
    "            alpha = (1/2) * np.log((1 - error) / (error))\n",
    "\n",
    "            # record the classifier and alpha\n",
    "            self.predicts.append((weak_clf, alpha))\n",
    "\n",
    "            # update distribution by -1 * alpha * y_pred * y_data\n",
    "            for i in range(len(sampleWeight)):\n",
    "                sampleWeight[i] = sampleWeight[i] * np.exp(-1 * alpha * y_pred[i] * signedY[i])\n",
    "                sampleWeight[i] = sampleWeight[i]/ np.sum(sampleWeight) # normalize\n",
    "            sampleWeight = np.array(sampleWeight)\n",
    "\n",
    "            # resample with the new weights\n",
    "            data = [i for i in range(len(x_data))]\n",
    "            idx = random.choices(data, weights=sampleWeight, k=len(sampleWeight))\n",
    "            x = self.x_data[idx]\n",
    "            y = self.y_data[idx]\n",
    "\n",
    "    def predict(self, x_data):\n",
    "\n",
    "        prediction = np.array([clf.predict(x_data) for clf, alpha in self.predicts])\n",
    "        predictions = np.zeros(len(x_data)) # final prediction\n",
    "\n",
    "        for i in range(len(self.predicts)):\n",
    "            y_pred = np.array(self.predicts[i][0].predict(x_data))\n",
    "            y_pred[y_pred == 0] = -1\n",
    "            predictions += self.predicts[i][1] * y_pred # strong classifier\n",
    "\n",
    "        predictions = np.sign(predictions)\n",
    "        predictions[predictions < 0] = 0\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4.1\n",
    "Show the accuracy score of validation data by `n_estimators=10` and `n_estimators=100`, respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost (n_estimators=10) accuracy: 0.9433333333333334\n",
      "AdaBoost (n_estimators=100) accuracy: 0.9766666666666667\n"
     ]
    }
   ],
   "source": [
    "clf_adaboost_10 = AdaBoost(n_estimators=10)\n",
    "clf_adaboost_10.fit(x_train, y_train)\n",
    "y_pred = clf_adaboost_10.predict(x_val)\n",
    "print(\"AdaBoost (n_estimators=10) accuracy:\", accuracy(y_pred, y_val))\n",
    "\n",
    "clf_adaboost_100 = AdaBoost(n_estimators=100)\n",
    "clf_adaboost_100.fit(x_train, y_train)\n",
    "y_pred = clf_adaboost_100.predict(x_val)\n",
    "print(\"AdaBoost (n_estimators=100) accuracy:\", accuracy(y_pred, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "implement the Random Forest algorithm by using the CART you just implemented from question 2. You should implement three arguments for the Random Forest.\n",
    "\n",
    "1. **n_estimators**: The number of trees in the forest. \n",
    "2. **max_features**: The number of random select features to consider when looking for the best split\n",
    "3. **bootstrap**: Whether bootstrap samples are used when building tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "class RandomForest():\n",
    "    def __init__(self, n_estimators, max_features, boostrap=True, criterion='gini', max_depth=None):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.max_features = int(max_features)\n",
    "        self.bootstrap = boostrap\n",
    "        self.criterion = criterion\n",
    "        self.tree = [] # for storing the classifiers and the chosen feature\n",
    "\n",
    "    def fit(self, x_data, y_data):\n",
    "        \n",
    "        for epoch in range(self.n_estimators):\n",
    "\n",
    "            # implement a tree for each epoch\n",
    "            tree = DecisionTree(criterion=self.criterion, max_depth = self.max_depth, max_features=self.max_features)\n",
    "            \n",
    "            if self.bootstrap:\n",
    "                used = np.random.choice(x_data.shape[0],  x_data.shape[0], replace=True)\n",
    "                x_sample, y_sample = x_data[used], y_data[used]\n",
    "            else:\n",
    "                x_sample, y_sample = x_data, y_data\n",
    "\n",
    "            # train with the chosen data\n",
    "            tree.fit(x_sample, y_sample)\n",
    "            self.tree.append(tree)\n",
    "\n",
    "    def predict(self, x_data):\n",
    "        \n",
    "        prediction = np.array([tree.predict(x_data) for tree in self.tree])\n",
    "        prediction = np.swapaxes(prediction, 0, 1)\n",
    "\n",
    "        # vote for the class which is often predicted\n",
    "        y_pred = [Counter(predict).most_common(1)[0][0] for predict in prediction]\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5.1\n",
    "Using `criterion=gini`, `max_depth=None`, `max_features=sqrt(n_features)`, showing the accuracy score of validation data by `n_estimators=10` and `n_estimators=100`, respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 618 is out of bounds for axis 0 with size 4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/linyurou/2022_Fall_ML/HW3/HW3.ipynb Cell 26\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/linyurou/2022_Fall_ML/HW3/HW3.ipynb#X33sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m clf_10tree \u001b[39m=\u001b[39m RandomForest(n_estimators\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, max_features\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39msqrt(x_train\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]))\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/linyurou/2022_Fall_ML/HW3/HW3.ipynb#X33sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m clf_10tree\u001b[39m.\u001b[39;49mfit(x_train, y_train)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/linyurou/2022_Fall_ML/HW3/HW3.ipynb#X33sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m y_pred \u001b[39m=\u001b[39m clf_10tree\u001b[39m.\u001b[39mpredict(x_val)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/linyurou/2022_Fall_ML/HW3/HW3.ipynb#X33sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mRandom Forest (n_estimators=10) accuracy:\u001b[39m\u001b[39m\"\u001b[39m, accuracy(y_pred, y_val))\n",
      "\u001b[1;32m/Users/linyurou/2022_Fall_ML/HW3/HW3.ipynb Cell 26\u001b[0m in \u001b[0;36mRandomForest.fit\u001b[0;34m(self, x_data, y_data)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/linyurou/2022_Fall_ML/HW3/HW3.ipynb#X33sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbootstrap:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/linyurou/2022_Fall_ML/HW3/HW3.ipynb#X33sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     used \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mchoice(x_data\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m],  x_data\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], replace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/linyurou/2022_Fall_ML/HW3/HW3.ipynb#X33sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     x_sample, y_sample \u001b[39m=\u001b[39m usedFeature[used], y_data[used]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/linyurou/2022_Fall_ML/HW3/HW3.ipynb#X33sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/linyurou/2022_Fall_ML/HW3/HW3.ipynb#X33sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     x_sample, y_sample \u001b[39m=\u001b[39m usedFeature, y_data\n",
      "\u001b[0;31mIndexError\u001b[0m: index 618 is out of bounds for axis 0 with size 4"
     ]
    }
   ],
   "source": [
    "clf_10tree = RandomForest(n_estimators=10, max_features=np.sqrt(x_train.shape[1]))\n",
    "clf_10tree.fit(x_train, y_train)\n",
    "y_pred = clf_10tree.predict(x_val)\n",
    "print(\"Random Forest (n_estimators=10) accuracy:\", accuracy(y_pred, y_val))\n",
    "\n",
    "clf_100tree = RandomForest(n_estimators=100, max_features=np.sqrt(x_train.shape[1]))\n",
    "clf_100tree.fit(x_train, y_train)\n",
    "y_pred = clf_100tree.predict(x_val)\n",
    "print(\"Random Forest (n_estimators=100) accuracy:\", accuracy(y_pred, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5.2\n",
    "Using `criterion=gini`, `max_depth=None`, `n_estimators=10`, showing the accuracy score of validation data by `max_features=sqrt(n_features)` and `max_features=n_features`, respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest (max_features = sqrt(n_features)) accuracy: 0.48\n",
      "Random Forest (max_features = n_features) accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "clf_random_features = RandomForest(n_estimators=10, max_features=np.sqrt(x_train.shape[1]))\n",
    "clf_random_features.fit(x_train, y_train)\n",
    "y_pred = clf_random_features.predict(x_val)\n",
    "print(\"Random Forest (max_features = sqrt(n_features)) accuracy:\", accuracy(y_pred, y_val))\n",
    "\n",
    "clf_all_features = RandomForest(n_estimators=10, max_features=x_train.shape[1])\n",
    "clf_all_features.fit(x_train, y_train)\n",
    "y_pred = clf_all_features.predict(x_val)\n",
    "print(\"Random Forest (max_features = n_features) accuracy:\", accuracy(y_pred, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Note: Use majority votes to get the final prediction, you may get slightly different results when re-building the random forest model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6. Train and tune your model on a real-world dataset\n",
    "Try you best to get higher accuracy score of your model. After parameter tuning, you can train your model on the full dataset (train + val).\n",
    "- Feature engineering\n",
    "- Hyperparameter tuning\n",
    "- Implement any other ensemble methods, such as gradient boosting. Please note that you **can not** call any package. Also, only ensemble method can be used. Neural network method is not allowed to used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_your_model(data):\n",
    "    \n",
    "    x_train = train_df.drop(['price_range'], axis=\"columns\").values\n",
    "    y_train = train_df['price_range'].values\n",
    "\n",
    "    model = None\n",
    "    max_accuracy = 0\n",
    "\n",
    "    # Decision Tree maximum accuracy = 0.936\n",
    "    # model = DecisionTree(criterion='gini', max_depth=100)\n",
    "    # model.fit(x_train, y_train)\n",
    "\n",
    "    # AdaBoost maximum accuracy = 0.963\n",
    "    model = AdaBoost(n_estimators=200)\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    # Random Forest maximum accuracy = 0.963\n",
    "    # model = RandomForest(n_estimators=100, max_depth=30, max_features=x_train.shape[1])\n",
    "    # model.fit(x_train, y_train)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of tuned-model:  0.9766666666666667\n"
     ]
    }
   ],
   "source": [
    "my_model = train_your_model(train_df)\n",
    "y_pred = my_model.predict(x_val)\n",
    "print(\"Accuracy of tuned-model: \", accuracy(y_pred, y_val))\n",
    "\n",
    "# train with train and validation dataset\n",
    "finalTrain_df = pd.concat([train_df, val_df])\n",
    "my_model = train_your_model(finalTrain_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/linyurou/2022_Fall_ML/HW3/HW3.ipynb Cell 32\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/linyurou/2022_Fall_ML/HW3/HW3.ipynb#X45sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m y_pred \u001b[39m=\u001b[39m my_model\u001b[39m.\u001b[39mpredict(x_test)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_test' is not defined"
     ]
    }
   ],
   "source": [
    "y_pred = my_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert y_pred.shape == (500, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supplementary\n",
    "If you have trouble to implement this homework, TA strongly recommend watching [this video](https://www.youtube.com/watch?v=LDRbO9a6XPU), which explains Decision Tree model clearly. But don't copy code from any resources, try to finish this homework by yourself! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DO NOT MODIFY CODE BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'y_test.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/linyurou/2022_Fall_ML/HW3/HW3.ipynb Cell 37\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/linyurou/2022_Fall_ML/HW3/HW3.ipynb#X52sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/linyurou/2022_Fall_ML/HW3/HW3.ipynb#X52sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m accuracy_score\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/linyurou/2022_Fall_ML/HW3/HW3.ipynb#X52sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m y_test \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m'\u001b[39;49m\u001b[39my_test.csv\u001b[39;49m\u001b[39m'\u001b[39;49m)[\u001b[39m'\u001b[39m\u001b[39mprice_range\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mvalues\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/linyurou/2022_Fall_ML/HW3/HW3.ipynb#X52sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mTest-set accuarcy score: \u001b[39m\u001b[39m'\u001b[39m, accuracy_score(y_test, y_pred))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/threePointEight/lib/python3.8/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/threePointEight/lib/python3.8/site-packages/pandas/io/parsers/readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    665\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    666\u001b[0m     dialect,\n\u001b[1;32m    667\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    676\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    677\u001b[0m )\n\u001b[1;32m    678\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 680\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/threePointEight/lib/python3.8/site-packages/pandas/io/parsers/readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    572\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    574\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    577\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    578\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/threePointEight/lib/python3.8/site-packages/pandas/io/parsers/readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    932\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 933\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/threePointEight/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1213\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1214\u001b[0m \u001b[39m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m \u001b[39m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[1;32m   1216\u001b[0m \u001b[39m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[0;32m-> 1217\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(  \u001b[39m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[1;32m   1218\u001b[0m     f,\n\u001b[1;32m   1219\u001b[0m     mode,\n\u001b[1;32m   1220\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1221\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1222\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1223\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1224\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1225\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1226\u001b[0m )\n\u001b[1;32m   1227\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1228\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/threePointEight/lib/python3.8/site-packages/pandas/io/common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    784\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    785\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    786\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    787\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    788\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    790\u001b[0m             handle,\n\u001b[1;32m    791\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    792\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    793\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    794\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    795\u001b[0m         )\n\u001b[1;32m    796\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    797\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    798\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'y_test.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_test = pd.read_csv('y_test.csv')['price_range'].values\n",
    "\n",
    "print('Test-set accuarcy score: ', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** We will check your result for Question 3 manually *** (5 points)\n",
      "*** We will check your result for Question 6 manually *** (20 points)\n",
      "Approximate score range: 45.0 ~ 70.0\n",
      "*** This score is only for reference ***\n"
     ]
    }
   ],
   "source": [
    "def discrete_checker(score, thres, clf, name, x_train, y_train, x_test, y_test):\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "    if accuracy_score(y_test, y_pred) - thres >= 0:\n",
    "        return score\n",
    "    else:\n",
    "        print(f\"{name} failed\")\n",
    "        return 0\n",
    "\n",
    "\n",
    "def patient_checker(score, thres, CLS, kwargs, name,\n",
    "                    x_train, y_train, x_test, y_test, patient=10):\n",
    "    while patient > 0:\n",
    "        patient -= 1\n",
    "        clf = CLS(**kwargs)\n",
    "        clf.fit(x_train, y_train)\n",
    "        y_pred = clf.predict(x_test)\n",
    "        if accuracy_score(y_test, y_pred) - thres >= 0:\n",
    "            return score\n",
    "    print(f\"{name} failed\")\n",
    "    print(\"Considering the randomness, we will check it manually\")\n",
    "    return 0\n",
    "\n",
    "\n",
    "def load_dataset():\n",
    "    file_url = \"http://storage.googleapis.com/download.tensorflow.org/data/abalone_train.csv\"\n",
    "    df = pd.read_csv(\n",
    "        file_url,\n",
    "        names=[\"Length\", \"Diameter\", \"Height\", \"Whole weight\", \"Shucked weight\",\n",
    "               \"Viscera weight\", \"Shell weight\", \"Age\"]\n",
    "    )\n",
    "\n",
    "    df['Target'] = (df[\"Age\"] > 15).astype(int)\n",
    "    df = df.drop(labels=[\"Age\"], axis=\"columns\")\n",
    "\n",
    "    train_idx = range(0, len(df), 10)\n",
    "    test_idx = range(1, len(df), 20)\n",
    "\n",
    "    train_df = df.iloc[train_idx]\n",
    "    test_df = df.iloc[test_idx]\n",
    "\n",
    "    x_train = train_df.drop(labels=[\"Target\"], axis=\"columns\")\n",
    "    feature = x_train.columns.values\n",
    "    x_train = x_train.values\n",
    "    y_train = train_df['Target'].values\n",
    "\n",
    "    x_test = test_df.drop(labels=[\"Target\"], axis=\"columns\")\n",
    "    x_test = x_test.values\n",
    "    y_test = test_df['Target'].values\n",
    "    return x_train, y_train, x_test, y_test, feature\n",
    "\n",
    "\n",
    "score = 0\n",
    "\n",
    "data = np.array([1, 2])\n",
    "if abs(gini(data) - 0.5) < 1e-4:\n",
    "    score += 2.5\n",
    "else:\n",
    "    print(\"gini test failed\")\n",
    "\n",
    "if abs(entropy(data) - 1) < 1e-4:\n",
    "    score += 2.5\n",
    "else:\n",
    "    print(\"entropy test failed\")\n",
    "\n",
    "x_train, y_train, x_test, y_test, feature = load_dataset()\n",
    "\n",
    "score += discrete_checker(5, 0.9337,\n",
    "                          DecisionTree(criterion='gini', max_depth=3),\n",
    "                          \"DecisionTree(criterion='gini', max_depth=3)\",\n",
    "                          x_train, y_train, x_test, y_test\n",
    "                          )\n",
    "\n",
    "score += discrete_checker(2.5, 0.9036,\n",
    "                          DecisionTree(criterion='gini', max_depth=10),\n",
    "                          \"DecisionTree(criterion='gini', max_depth=10)\",\n",
    "                          x_train, y_train, x_test, y_test\n",
    "                          )\n",
    "\n",
    "score += discrete_checker(2.5, 0.9096,\n",
    "                          DecisionTree(criterion='entropy', max_depth=3),\n",
    "                          \"DecisionTree(criterion='entropy', max_depth=3)\",\n",
    "                          x_train, y_train, x_test, y_test\n",
    "                          )\n",
    "\n",
    "print(\"*** We will check your result for Question 3 manually *** (5 points)\")\n",
    "\n",
    "score += patient_checker(\n",
    "    7.5, 0.91, AdaBoost, {\"n_estimators\": 10},\n",
    "    \"AdaBoost(n_estimators=10)\",\n",
    "    x_train, y_train, x_test, y_test\n",
    ")\n",
    "\n",
    "score += patient_checker(\n",
    "    7.5, 0.87, AdaBoost, {\"n_estimators\": 100},\n",
    "    \"AdaBoost(n_estimators=100)\",\n",
    "    x_train, y_train, x_test, y_test\n",
    ")\n",
    "\n",
    "score += patient_checker(\n",
    "    5, 0.91, RandomForest,\n",
    "    {\"n_estimators\": 10, \"max_features\": np.sqrt(x_train.shape[1])},\n",
    "    \"RandomForest(n_estimators=10, max_features=sqrt(n_features))\",\n",
    "    x_train, y_train, x_test, y_test\n",
    ")\n",
    "\n",
    "score += patient_checker(\n",
    "    5, 0.91, RandomForest,\n",
    "    {\"n_estimators\": 100, \"max_features\": np.sqrt(x_train.shape[1])},\n",
    "    \"RandomForest(n_estimators=100, max_features=sqrt(n_features))\",\n",
    "    x_train, y_train, x_test, y_test\n",
    ")\n",
    "\n",
    "score += patient_checker(\n",
    "    5, 0.92, RandomForest,\n",
    "    {\"n_estimators\": 10, \"max_features\": x_train.shape[1]},\n",
    "    \"RandomForest(n_estimators=10, max_features=n_features)\",\n",
    "    x_train, y_train, x_test, y_test\n",
    ")\n",
    "\n",
    "print(\"*** We will check your result for Question 6 manually *** (20 points)\")\n",
    "print(\"Approximate score range:\", score, \"~\", score + 25)\n",
    "print(\"*** This score is only for reference ***\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('threePointEight')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "e4a761a54976c9b97c30c3b3dcb15010d667d500d03cac3f5b2e6469512b4980"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
